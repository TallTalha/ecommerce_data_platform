# E- Ticatert Sitesi Ä°Ã§in Veri MÃ¼hendisliÄŸi

# AmaÃ§
"Owl Shop" tarafÄ±ndan sÃ¼rekli olarak Ã¼retilen e-ticaret verilerini (mÃ¼ÅŸteri bilgileri, sipariÅŸler, web sitesi olaylarÄ±) yakalayan, iÅŸleyen, depolayan ve analiz eden uÃ§tan uca bir veri platformu tasarlamak ve mantÄ±ÄŸÄ±nÄ± kurmak.

# Teknolojiler
- Apache Kafka
- Apache Spark
- Apache Airflow
- MongoDB

# ğŸ“Š AkÄ±ÅŸ DiyagramÄ±
AÅŸaÄŸÄ±da veri platformumuzun genel akÄ±ÅŸÄ± yer almaktadÄ±r:

![Workflow image](images/Workflow.svg)

---

```plaintext

ecommerce_data_platform/

â”œâ”€â”€ dags/ # Airflow DAG dosyalarÄ±mÄ±z burada yaÅŸayacak
â”‚ â”‚
â”‚ â””â”€â”€ process_daily_data.py
â”‚
â”œâ”€â”€ data/ # Lokal Veri GÃ¶lÃ¼mÃ¼z. Spark iÅŸlerinin sonuÃ§larÄ± (Parquet) buraya yazÄ±lacak.
â”‚ â”‚
â”‚ â””â”€â”€ processed/
â”‚ â”‚
â”‚ â”œâ”€â”€ customer_profiles/
â”‚ â”‚
â”‚ â””â”€â”€ sales_reports/Add commentMore actions
â”‚
â”œâ”€â”€ docker-compose.yml # Tek komutla tÃ¼m altyapÄ±yÄ± (Kafka, Mongo, Airflow vb.) baÅŸlatan dosya
â”‚
â”œâ”€â”€ notebooks/ # EDA
â”‚  â”‚
â”‚  â””â”€â”€ initial_data_exploration.ipynb
â”‚
â”œâ”€â”€ spark_jobs/ # Spark ile yazacaÄŸÄ±mÄ±z veri iÅŸleme betiklerimiz
â”‚ â”‚
â”‚ â”œâ”€â”€ streaming_frontend_events.py
â”‚ â”‚
â”‚ â””â”€â”€ batch_process_orders.py
â”‚
â”œâ”€â”€ configs/ # KonfigÃ¼rasyon dosyalarÄ±
â”‚ â”‚
â”‚ â””â”€â”€ owl_shop_config.yaml
â”‚
â””â”€â”€ README.md # Projenin ne yaptÄ±ÄŸÄ±nÄ± ve nasÄ±l Ã§alÄ±ÅŸtÄ±rÄ±lacaÄŸÄ±nÄ± anlatan ana dosya

```